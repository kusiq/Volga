# Volga Generative pre-trained transformer

![Frame 1 (1)](https://github.com/user-attachments/assets/3f0a29d9-ff68-48c7-94f6-cdfc5c243d89)

# Volga Alpha model - v0.4 MEDVED' (WIP)

Языковая модель "Vолга" доученая на базе Qwen2.5-7B (7.620.000.000 параметров). Обучена на содержании 1% русскоязычной википедии.

Кодовое название версии 0.4 - "Медведь". Имеет возможность дать ответ на вопрос.

# Volga Alpha model - v0.3 KROT

Языковая модель "Vолга" доученая на базе Qwen2.5-0.5B (496.000.000 параметров). Обучена на содержании 0.01% русскоязычной википедии.

Кодовое название версии 0.3 - "Крот". Имеет возможность дать ответ на вопрос.

# Volga Alpha model - v0.2 BELKA

Языковая модель "Vолга" доученая на базе GPT2 (124.000.000 параметров). На данный момент обучена на датасете произведений А. С. Пушкина.

Кодовое название версии 0.2 - "Белка". Имеет возможность генерировать продолжение строки стиха на основе текстов поэта.

# Volga Alpha model - v0.1 

Инициализация модели обучения на GPT2, код для создания небольшой модели
